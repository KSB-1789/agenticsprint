```
# ğŸš€ AgenticSprint Prototype

An AI-powered assistant prototype built for **AgenticSprint: From Prototype to Future Tech** (Hackathon, Sept 15â€“17).  
This project demonstrates a simple **frontend (Streamlit)** connected to a **backend (FastAPI)**, ready for integration with AI models.

---
## ğŸ“‚ Project Structure
## ğŸ“‚ Project Structure
```

.
â”œâ”€â”€ app.py           # Streamlit frontend (chat UI)
â”œâ”€â”€ backend.py       # FastAPI backend (dummy AI response)
â”œâ”€â”€ requirements.txt # Python dependencies
â””â”€â”€ README.md        # Project documentation

````

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository
```bash
git clone <repo-link>
cd <repo-folder>
````

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Run the App

### Start Backend (Terminal 1)

```bash
uvicorn backend:app --reload
```

### Start Frontend (Terminal 2)

```bash
streamlit run app.py
```

The app will open automatically at:
ğŸ‘‰ [http://localhost:8501](http://localhost:8501)

---

## ğŸ’¡ Features

* ğŸ–¥ï¸ **Frontend:** Chat-style UI built with Streamlit
* âš™ï¸ **Backend:** FastAPI service (currently dummy AI response)
* ğŸ”— **Integration:** Streamlit calls backend API for answers
* ğŸ¯ **Hackathon Ready:** Easy to extend with real AI models (Kritikaâ€™s part)

---

## ğŸ”„ Demo Modes

The project supports **two demo modes** (to avoid failure during judging):

1. **Real Mode:** Connects to backend API (FastAPI with AI model).
2. **Dummy Mode:** Uses placeholder response (safe fallback if backend fails).

---

## ğŸ‘©â€ğŸ’» Team Roles

* **Karanveer Singh** â€“ Frontend, repo, documentation, pitch
* **Kritika** â€“ Backend AI integration (RTX 3050)
* **Eknoor** â€“ Mac demo setup, presentation polish

---

## ğŸŒŸ Next Steps

* Replace dummy backend with AI pipeline (LLMs + vector DB).
* Add memory + multi-agent orchestration.
* Deploy final version for hackathon demo.

```

---


